Definition
- AI(Artificial Intelligence): 주어진 환경 및 데이터를 인지, 학습, 추론을 통해 목표 달성을 하도록 예측, 행동, 선택, 계획하는 시스템
- ML(Machine Learning): AI 범주 내에서 데이터로부터 학습하여 목적을 달성하는 접근 방법론. 예) 언어 모델, 이미지 분류 모델, 추천 시스템
- DL(Deep Learning): ML 범주 내에서 신경망(Neural Network) 함수를 사용한 학습 방법론 
- ML이 아닌 AI 시스템: 규칙 기반 시스템, 휴리스틱 기반 (최적화) 알고리즘

학습과 추론
- 학습(Learning): 입력(feature) -> 출력(label)의 관계를 찾는 과정. 평균 관계를 하나의 함수로 표현하는 것이 목적이지만 관계를 표현할 수 있는 함수는 무수히 많이 존재한다.
  - 가설 공간(hypothesis space): 관계를 표현할 수 있는 모든 후보 함수들의 모음 - 피쳐 공간과 라벨 공간 위에서 정의된 함수들의 집합 $F$
  - 모델(model): 가설 공간 F에 속한 특정 함수 $f$
  - 학습이란, 주어진 데이터와 성능 척도를 바탕으로 가설공간 $F$를 설계하고, 그 후보들 중 최적의 모델을 선택하는 과정이라고 할 수 있다.
  - 학습을 하는 이유
    - 잘 학습된 모델 $f$가 있으면, 새로운 입력에 대한 반응/목표를 예측할 수 있다.
    - features $X$ 중 어떤 특성이 $Y$를 설명하는데 중요하고, 어떤 것이 덜 중요(혹은 무관)한지 알 수 있다.
    - $f$의 복잡도에 따라, 각 구성요소 $X_j$가 $Y$에 어떻게 영향을 미치는지(증감 방향, 민감도 등) 이해할 수 있다.
- 추론: 만들어진 모델을 바탕으로 결과를 예
- 함수형 모델의 형태: $Y = f(X_1, X_2, \ldots, X_i) + \epsilon$
  - $Y$: 예측하려는 라벨 변수
  - $X_i$: i번째 피쳐

- 머신러닝 파이프라인
  - 데이터수집 -> 전처리(EDA) -> 모델학습 -> 예측 -> 평가
  
Machine Learning(ML)
- 지도 학습: 명시적인 답이 주어진 상태로 기계학습
  - 용어 정리
    - 데이터: 입력(feature)과 정답(label)이 쌍으로 있는 데아터
    - 목표: 새 입력이 들어오면 적절한 정답을 예측하는 규칙을 학습
    - 회귀: 예측값이 수
    - 분류: 예측값이 범주
    - 예측값($\hat{y}$): 모델이 내놓은 결과
    - 오류(error): 예측값과 라벨 간의 차이
  - 회귀(regression): 연속적인 수치에 대한 모델 예측
    - 평균제곱오차(MSE, Mean Squared Error): 각 데이터에서 정답과 예측의 평균 제곱 차이값. 큰 오류를 더 크게 벌(punishment)주는 경향이 있다. 
    $$MSE = \frac{1}{n} \sum_{i=1}^{n} (y_i - \hat{y}_i)^2$$
      - RMSE:  $\sqrt{MSE}$., 데이터와 같은 단위를 쓰고 싶을 경우 사용
    - 결정계수 ($R^2$) : 라벨의 분산 중에서 특성으로 설명되는 비율. 평균만 사용하는 '단순한 예측'과 비교하여 얼마나 더 잘 맞는 모델인지 0~1 사이의 값으로 나타낸 것. 1에 가까울수록 설명력이 높다. 이론상 결정계수가 음수일 수도 있으나, 이 경우 예측 모델이 단순한 예측보다도 성능이 떨어짐을 의미한다.
    $$R^2 = 1 - \frac{\sum_{i=1}^{n} (y_i - \hat{y}_i)^2}{\sum_{i=1}^{n} (y_i - \bar{y}_i)^2} \qquad \bar{y} = y_i들의\;평균값$$  
  - 분류(Classification): 범주 라벨에 대한 모델 예측
    - 정확도(accuracy): 전체 중 맞춘 비율. 단, 이는 절대적인 안전성을 보장하지 않는다. 예를 들어 불균형 데이터(양성 1%, 음성 99%)에서는 전부 음성이라 해도 정확도가 99%로 보일 수 있다. 따라서, 항상 다른 지표도 병행하여 확인할 필요가 있다.
    - 혼동행렬(Confusion Matrix): 예측과 실제 값 사이의 관계를 행렬 형태로 표현한 것.
      - TP(True Positive), TN(True Negative): 실제와 예측이 합치
      - FP(False Positive, 오탐), FN(False Negative, 누락): 실제와 예측이 불일치
      - 정밀도(precision): TP / (TP + FP)
      - 재현율(sensitivity, recall): TP / (TP + FN)
      - F1-score: 정밀도와 재현율의 조화평균, F1 = 2 * ((정밀도 * 재현율)/(정밀도 + 재현율))
  - 학습 모델의 성능 평가
    - 오버피팅(overfitting, 과적합): 훈련 데이터의 우연한 패턴/잡음까지 외워버려서 훈련에서는 잘 맞지만 테스트에서는 성능이 나빠지는 현상.
      - 표본 의존,불안성: 훈련 데이터는 모집단의 일부 표본이기 때문에 우연한 잡음이 섞일 수 있다. 이것에만 과하게 맞추어 학습할 경우 샘플 몇개만 바뀌어드 예측이 크게 흔들린다.
      - 일반화 실패: 보지 못한 데이터에 대한 오류가 커질 수 있다. 모집단 성능과 격차가 벌어진다.
    - 언더피팅(underfitting): 모델이 단순하거나 학습이 완료되지 않은 경우. 중요한 패턴을 놓칠 가능성이 높다.
    - 테스트 예측오류 계산
      - 이상적 케이스: 충분히 큰 별도 테스트 데이터셋을 마련하기. 현실에서는 테스트만을 위한 데이터를 갖기에 데이터 자체가 부족할 수 있다.
      - 대안: 재표본화(resampling)를 통한 테스트 오류 추정
        - 데이터를 나눠 여러 번 훈련 -> 평가를 반복하여 테스트 오류를 가늠한다.
        - 별도의 테스트 데이터 없이 데이터를 더 효율적으로사용하여 일반화 오차를 추정할 수 있다.
        - 검증셋(validation set, 홀드아웃) 방법
          - 가용 샘플들을 무작위로 훈련셋과 검증셋(hold-out)으로 분할하여 훈련셋으로는 모델 적합, 검증셋으로는 예측 후 검증 오류를 계산한다. 검증 오류의 경우 일반적으로 정량 반응은 MSE, 범주 반응은 오분류율(또는 F1-score)을 측정한다.
          - 검증 절차: 데이터 순서를 무작위로 셔플링 후 두 부분으로 분할하여 학습은 훈련셋에서, 성능평가는 검증셋에서 수행한다.
        - K-겹 교차검증(K-fold Cross Validation)
- 비지도 학습: 정답(label) 없이 데이터의 구조, 패턴, 집단(잠재적 서브그룹)을 찾아내는 학습
  - 대표 과제: 군집화(clustering), 차원축소(PCA), 밀도추정/이상치 탐지
  - 출력 형태: 정답 예측이 아닌 구조/요약/표현(embedding)
  - clustering: 데이터 안에서 하위 집단(cluster)을 찾는 기법들의 총칭
    - 목표: 집단 내부는 서로 유사, 집단 간은 상이하도록 데이터를 분할한다.
    - 클러스터링 기법: K-means, 계층적 군집(hierarchical)
      - K-means 클러스터링: 클러스터 수(K)를 미리 정한 후 분할한다.
        - 목표: 클러스터 내부 변동(Within-Cluster Variation)이 작은 분할이 되도록, 즉 클러스터 내부 변동의 합이 최소가 되도록 분할을 찾는다.
        - 알고리즘
          - 1. 초기화: 관측치들에 무작위로 1 ~ K 클러스터를 임시로 부여
          - 2. 반복(할당이 더 이상 바뀌지 않을때 까지)
            - a. 각 클러스터의 중심(centroid) 계산(특성 평균 벡터)
            - b. 각 관측치를 가장 가까운 중심의 클러스터에 재할당(거리 예: 유클리드)
          - 반복을 거듭함에 따라 목표함수 값을 감소시킨다.
    - 계층적 군집(Hierarchical Clustering)
      - k-means vs hierarchical
        - k-means는 클러스터 수를 미리 지정해야 하는 단점이 존재한다.
        - 계층적 군집은 군집 수를 고정하지 않고 전체 구조를 덴드로그램으로 제공
      - 알고리즘(상향식)
        - 1. n개 관측에 대해 쌍별 비유사도 계산, 각 관측치를 하나의 클러스터로 시작
        - 2. i=n, n-1, ... 2에 대해 반복
          - a. i개 클러스터 간 쌍별 비유사도를 모두 계산해 가장 유사한 두 클러스터를 병합
          - b. 병합후 남은 i-1개 클러스터 사이의 새 비유사도를 다시 계산
        - 계층적 군집 병합: 데이터들이 점차 큰 클러스터로 합쳐지는 과정. 매 단계에서 클러스터 간의 병합이 이루어지며 1개의 단일 클러스터가 될때까지 진행한다.
          - 매 단계에서 모든 클러스터 쌍 간의 거리를 계산해야 하므로 데이터가 많은 경우 K-means에 비하여 계산량이 많다.
        - link의 유형 - 군집 간 거리의 결정
          - single link(최소 거리): 두 클러스터 내 데이터 쌍별 거리 중 최소값
          - complete link(최대 거리): 두 클러스터 내 데이터 쌍별 거리 중 최대값
          - average link(평균 거리): 두 클러스터 내 데이터 쌍별 거리의 평균
    - 클러스터링 체크리스트
      - 스케일링: 표준화(평균 0, 표준편차 1로 입력 변수 변환)가 필요하다. 변수 단위 차이의 영향이 크기 때문에.
      - 몇 개의 클러스터가 적합한가?: 두 방식 모두 일반적으로 합의된 정답이 없다. 따라서 단일 시도가 아닌 다회차의 시도가 권장된다.
- 강화 학습: agent가 주어진 state에 대해 어떤 action을 취하면 reward를 얻으면서 학습

---
선형 회귀
- 입력 변수와 출력 변수 사이의 관계를 직선형태로 근사하여 예측하는 통계적 방법으로, 지도학습의 가장 기초가 되는 접근 중 하나이다. 단순해 보이지만, 개념적으로도 실무적으로도 매우 유용한 방식이다.
- 단순선형회귀(simple linear regression): 한개의 설명변수(X)와 하나의 반응변수(Y)에 사이의 관계를 가장 잘 설명할 수 있는 직선 ŷ을 찾는 방법.
  - 모형 가정: Y = β0 + β1X + ε
  - 최소제곱법(least square): 실제 관측값과 예측값의 차이(잔차, residual)를 제곱해 합한 값인 잔차제곱합(rss)을 최소화하는 방법.
- 다중선형회귀(multiple linear regression): 독립 변수가 여러개 존재할 때 사용하는 회귀분석 기법
  - 모형 가정 ŷi = β0 + β1xi1 + β2xi2 + ... + βpxip
- 주의점
  - 훈련 데이터에서의 성능: 회귀식을 만들때 최소제곱 해는 훈련 데이터만 보고 계산되는데, 학습에 사용된 훈련 데이터에서는 fitting이 잘 되어 있을 가능성이 높으나, 이는 테스트 성능의 과소평가를 유발할 가능성이 높다.
  - 테스트 성능 평가: 선형회귀도 변일반화 성능을 확인하기 위해서 훈련에 사용되지 않은 새로운 테스트 데이터에 적용해볼 필요가 있다. 수가 많거나 고차항을 사용할 경우 과적합 문제의 발생 가능성이 여전히 존재한다. 검증/교차검증을 통해서 적절한 적합을 찾을 수 있다.

---
분류(classification)
- 정해진 범주 중 하나로 지정하는 것.
- 범주형 변수: 수치의 크고 작음이 아니라 유한한 범주로 표현하는 변수
- 선형회귀는 예측값이 제한된 값(0~1 사이)을 갖게 할 수 없기 때문에 확률로 쓰기 부적절하다.
- 따라서, 시그모이드(sigmoid)함수를 활용하여 0~1 범위 내 확률값 예측을 보장할 수 있는 로지스틱 회귀 방식을 사용한다.
- 로지스틱 회귀(logistic regression)
  - sigmoid 함수: $y = \dfrac{e^z}{1 + e^z} = \dfrac{1}{1 + e^{-z}}$
  - sigmoid 함수에 z = β0 + β1x 식을 대입하고 확률 표기 p(x)를 활용하여 로지스틱 회귀의 모형식을 표현한다.
  - 로지스틱 함수 $p(x; \beta) = \dfrac{e^{\beta_0 + \beta_1 x}}{1 + e^{\beta_0 + \beta_1 x}}$
  - 오즈(odds): 성공(y=1)이 실패(y=0)에 확률에 비해 몇 배 더 높은지 나타내는 수치.
  $odds = \dfrac{p(y = 1|x)}{p(y = 0|x)} = \dfrac{p(y = 1|x)}{1 - p(y = 1|x)}$
  - 로짓 변환(logit, log odds): odds에 log를 취한 함수 형태. 로지스틱 모형에 로짓 변환을 취하면 선형 모형을 얻을 수 있다.
  - 우도(likelihood): 현재 확률 함수가 데이터를 얼마나 잘 설명하는지를 나타내는 지표. 모델의 학습은 우도 값을 높여 최대화가 되는 것을 목표로 하며 이를 MLE(Maximus Likelihood Estimation)이라 한다.

---
신경망모델
- 단순(1D) 선형모델 학습: 순차적으로 모수(parameter)를 조정하면서 찾아내는 선형회귀
- shallow network: piecewise-linear하게 모델을 근사하기
- 손실함수(loss function): 모델이 얼마나 잘못 예측하는지를 측정하는 함수
- 경사하강(gradient descent) 알고리즘: 손실함수 L[Φ]를 최소화하기 위해 파라미터 Φ를 반복적으로 갱신하는 알고리즘
  - 기울기 계산: 손실함수 L[Φ]를 파라미터 Φ에 대해 편미분 진행. 미분값의 반대방향으로 이동하면 손실함수가 줄어든다.
  - 과정 요약
    - 데이터 수집
    - 손실함수 구현(3D그래프 -> 2D등고선)
    - 선형함수 업데이트
  - Convex vs Non-convex
    - convex: 곡선이 항상 아래로 볼록(이계도함수가 항상 >=0). 그래프 위 임의 두점을 잇는 직선이 그래프 위 또는 같은 위치에 있음. 전역 최소값이 유일하기 때문에 최적화가 쉽다.
    - Non-convex: 곡선에 위로 볼록한 구간과 아래로 볼록한 구간이 혼재되어있는 경우. 두 점을 잇는 직선의 일부가 그래프 아래로 내려가는 구간이 존재. 여러개의 지역 최소값 또는 새들점이 존재하여 최적화가 어렵다.
  - 확률적 경사 하강법(Stochastic Gradient Descent, SGD)
    - Non-convex 문제에서 지역 최소점에 빠지기 쉬운 문제를 해결하기 위한 방식. 
    - 매 스텝마다 전체 데이터에 대한 미분값을 구하여 업데이트한다.(필연적으로 스텝별 개산양이 많아진다.) -> 이에 대한 대안으로, 전체 데이터를 한번에 쓰는 대신 무작위로 선택한 데이터 샘플을 사용한다.
역전파(Backpropagation)

---
워드 임베딩
- 원-핫 인코딩
  - 규칙 기반 혹은 통계적 자연어처리 연구의 대다수는 단어를 원자적 기호로 취급한다. 벡터 공간 관점에서 이는 한 원소만 1이고 나머지는 모두 0인 벡터를 의미한다. 이를 원-핫(one-hot) 표현이라 부르고, 단어를 원-핫 표현으로 바꾸는 과정을 원-핫 인코딩(one-hot encoding)이라 한다.
    - 데이터베이스에 따른 차원 수(단어 사전의 크기): 음성 데이터(2만) - Penn Treebank(PTB) 코퍼스(5만) - big vocab(50만) - Google 1T(1300만)
  - 문제점:
    - 검색 쿼리 벡터와 대상이 되는 문서 벡터들이 서료 직교하게 되어, 원-핫 벡터로는 유사도를 측정할 수 없다.
    - 차원의 저주(curse of dimensionality): 고차원의 희소 벡터를 다루기 위해서는 많은 메모리를 요구하고 차원이 커질수록 데이터가 점점 더 희소(sparse)해져 활용이 어렵다.
    - 의미적 정보 부족: 비슷한 단어라도 유사한 벡터로 표현되지 않는다. 예를 들어, '은행'과 '금융'은 의미적으로 밀접하지만, 원-핫 인코딩에서는 전혀 무관한 벡터로 취급된다.
- 워드 임베딩: 단어를 단어들 사이의 의미적 관계를 포착할 수 있는 밀집(dense)되고 연속적/분산적(distributed) 벡터 표현으로 나타내는 방법이다. 원-핫 인코딩에선 유사성이 있는 단어더라도 완전히 독립적인 벡터로 표현되는 반면, 워드 임베딩에선 두 단어의 벡터가 공간상 서로 가깝게 위치시켜 의미적 유사성을 반영할 수 있다.
  - Word2Vec: 2013년 구글에서 개발한 워드 임베딩 기법. 간단한 인공 신경망을 이용하여 단어의 표현을 학습한다.
    - 아이디어: 각 단어와 그 주변 단어들 간의 관계를 예측한다.
    - 알고리즘
      - Skip-grams(SG) 방식: 중심 단어를 통해 주변 단어들을 예측하는 방법이다. 
        - window size: 중심 단어 주변 몇개까지를 문맥으로 볼 것인가?
        - 장점
          - 단어의 위치에 크개 구애받지 않는다.  
          - 적은 데이터에도 잘 동작한다.
          - 희귀 단어나 구 표현에 강하다.
        - 단점: 학습 속도가 느리다.
      - Continuous Bag of Words(CBOW) 방식: 주변 단어들을 통해 중심 단어를 예측하는 방법이다. 문맥 단어들의 집합으로 중심 단어를 맞춘다.
        - 장점
          - 학습 속도가 빠르다.
          - 자주 나오는 단어에 강하다.
        - 단점: 희귀 단어 표현에 약하다.
- 순차적 데이터: 데이터가 입력되는 순서와 이 순서를 통해 입력되는 데이터들 사이의 관계가 중요한 데이터.
  - 특징
    - 데이터의 순서가 바뀌면 의미가 달라진다.
    - 장기 의존성(Long-term dependency): 멀리 떨어진 과거의 정보가 현재/미래에 영향을 준다.
    - 가변 길이(variable length): 데이터의 길이와 단어의 수가 일정치 않다.
  - 따라서, 순차적 데이터를 처리하려면 일반적인 모델들로는 불가능하고, sequential model이 필요하다.
    - RNN, LSTM, Transformer
- RNN(Recurrent Neural Network)
  - 전통적인 신경망과 달리, RNN은 이전 시점의 정보를 담는 hidden state를 갖는다. 따라서, 입력 시퀀스 벡터 x를 처리할 때, 각 시점마다 recurrence 수식을 적용하여 hidden state를 업데이트한다.
  - hidden state: $h_t = f_w(h_{t-1}, x_t)$
  - 특징
    - 한번에 하나의 요소를 처리하고 정보를 앞으로 전달한다. 이를 펼쳐서 보면 각 층이 하나의 시점을 나타내는 깊은 신경망처럼 보인다.
    - hidden state를 유지하면서 가변길이 데이터를 처리할 수 있다.
    - 과거 입력에 영향을 받는다.
  - 한계점 - 기울기 소실(vanishing gradient) 문제: 딥러닝에서 역전파 시 앞쪽 층의 기울기가 0에 가까워져서 장기 의존성 학습이 어려워지는 현상.
    - 역전파 과정에서 작은 값들이 계속 곱해지고, 과거 시점에서 온 오차 신호는 갈수록 더 작은 기울기를 갖게 된다. 즉, 파라미터들이 장기 의존성은 학습하지 못하고 단기 의존성만 포착하게 된다.
  - LSTM(Long-Short Term Memory): 기울기 소실 문제를 해결하기 위해 제안된 RNN의 한 종류
    - 시점 t에서 RNN은 길이가 n인 벡터 hidden state $h_t$와 cell state $C_t$를 갖는다.
    - LSTM은 cell state에서 정보를 읽고(read), 지우고(erase), 기록(write)할 수 있다.
    - 3가지 게이트를 통해 어떤 정보를 조작할지 결정한다.
      - Forget gate: 이전 cell state에서 무엇을 버리고 무엇을 유지할 지 결정한다.
      - Input gate: 새 정보 중 얼마나 cell state에 쓸지 결정한다.
      - Output gate: cell state 중 얼마나 hidden state로 내보낼지 결정한다.
---
언어모델
- 인간의 두뇌가 자연어를 생성하는 능력을 모방하는 모델. 단어 시퀀스 전체에 확률을 부여하여 문장의 자연스러움을 측정한다.
- N-gram 언어모델
  - n-gram: 연속된 n개의 단어 묶음
  - 다양한 n-gram이 얼마나 자주 등장하는지 통계를 수집하고, 이를 활용해 다음 단어를 예측한다.
- Nerual Machine Translation: 인공 신경망을 이용해 기계 번역을 수행하는 방법.
  - Seq2Seq(sequence-to-sequence): 인공 신경망 번역에 사용되는 두개의 RNN으로 이루어진 신경망 구조.
    - 번역 문제는 입출력의 길이가 다를 수 있기 때문에 길이가 다른 시퀀스 간의 매핑을 처리할 수 있어야 한다.
    - 입력 시퀀스를 한 타임스텝씩 읽어 고정된 차원의 큰 벡터 표현을 얻어내는 encoder와 얻은 벡터로부터 출력 시퀀스를 생성하는 decoder, 두 LSTM을 사용한다.


---
이미지 기반 학습 모델
- 완전 연결층(FCN, Fully-Connected Layer): 입력을 받아서 출력으로 변환하는 신경망의 기본 모듈
- 합성곱 레이어(CNN, Convolution Layer): 입력 이미지를 필터와 연산하여 특징 맵(feature map)을 뽑아내는 모듈. 1차원 구조로 변환하는 FCN과 달리 3차원 구조를 그대로 보존하면서 연산한다. 이 때, 필터의 깊이는 입력과 같아야 한다.
- 수용 영역(Receptive Field): CNN이 이미지를 처리하면서 한번에 볼수 있는 영역의 크기
  - CNN 레이어는 이미지의 작은 부분인 지역 정보를 추출하는데 유리하게 셜게되었다. 그러나, 이미지를 활용하는 다양한 작업에서는 이미지 전체(맥락) 의미 파악이 필요하다. 따라서, 지역정보 + 이미지 전체의 맥락을 이해 및 활용하기 위한 설계가 필요하다.
  - 고해상도 이미지를 처리할 때, 많은 레이어를 통과해야 하므로 연산, 비용, 학습 가능성을 고려하면 비실용적이다. 이는 입력 사이즈를 줄여 모델에 입력함으로써 해결 가능하다.
  -> 풀링(pooling)
    - 연산 효율성 확보: CNN 레이어의 출력을 줄여 연산 효율성을 확보할 수 있다.
    - 위치 변화 강건성: 입력 내 객체 위치가 다소 변해도 동일한 출력을 제공한다.
    - 맥스풀링: 정해진 커널 사이즈로 이미지를 나누어 각 영역 내 가장 큰 값을 선택하는 연산
    - 풀링 한계 개선 - 스트라이드 합성곱: 필터를 1칸씩이 아닌 스트라이드 값(S)만큼 이동한 후 출력 연산을 행한다.


---
foundation model
- 기계학습 모델의 이상과 현실
  - 이상: AI모델이 세상에서 발생 가능한 모든 데이터와 그 설명을 모두 기억하고 있음.
  - 현실: AI모델의 데이터를 패턴화하여 압축하고 그 과정에서 비슷함과 다름을 파악하고 패턴을 익히면서 새로운 데이터에 대한 일반화 능력이 생긴다.
- 파운데이션 모델: 대규모 데이터를 폭넓게 학습한 후, 다양한 문제에 빠르게 적응할 수 있는 범용 대형 AI모델.
  - 특징
    - 대규모: 트랜스포머 모델 + 대규모 언어 데이터 학습
      - 태스크에 상관없이 비슷한 패턴들이 등장하고 있다.
      - 주로 비지도학습(쉬운 데이터 수집 + 대규모 학습)으로 훈련된 모델들도 많이 등장
    - 적응성: 높은 파인튜닝 성능(높은 태스크 적응 성능)
    - 범용성: 다양한 작업, 한정되지 않는 출력 지원
  - 과거에는 매번 모델을 새로 학습했지만, 이제는 잘 학습된 모델들을 얼마나 잘 활용하는지가 핵심. 그러나, 파운데이션 모델 하나를 확보하는데 투여되는 계산 리소스는 일부 대규모 인프라 이에외는 감당하기 어렵다. 

---
Text Foundation Model - LLM(Large Language Model)
- 파운데이션 모델: 대량의 데이터를 기반으로 사전 학습된 대규모 AI 모델. 
  - 구성요소
    - 빅데이터: 인터넷에 존재하는 데이터 수는 기하급수적으로 증가하고 있고, 딥러닝 기반 AI 모델은 학습 데이터가 늘어날수록 성능이 증가한다.
    - 자가 학습(self-supervised learning) 알고리즘: 사람이 정답을 알려줄 필요가 없다.
    - 어텐션 기반 트랜스포머 모델: 더 많은 데이터를 학습할 수 있는 인공신경망 구조를 갖는다.
- 텍스트 파운데이션 모델(거대 언어 모델)
  - 기존 대비, 더 큰 모델(>7B)이  더 많은 데이터(>1T)에서 학습되어 창발성이 나타나기 시작한 언어 모델. 일반적으로, 거대 언어모델은 GPT와 같이 다음 토큰 예측을 통해 많은 텍스트 데이터에서 사전 학습된 트랜스포머 기반 모델을 의미한다.
  - 특이점
    - 규모의 법칙(scaling law): 더 많은 데이터, 더 큰 모델, 더 긴 학습이 더 좋은 성능으로 이어진다.
    - 창발성(emergent property): 특정 규모를 넘어설 때 갑자기 모델에서 발현되는 성질
      - 인-컨텍스트 학습(in-context learning): 주어진 설명과 예시만으로 새로운 태스크를 수월하게 수행할 수 있다.
      - 추론(reasoning) 능력
  - 폐쇄형(Closed) LLM: ChatGPT(OpenAI), Claude(Anthropic), Gemini(Google)
    - 장점: 일반적으로 더 우수한 성능 및 최신 기능을 갖고 있으며 사용하기 쉽다.
    - 단점: 사용시마다 비용이 발생하고, 모델이나 출력에 대한 정보의 제공이 제한적이다.
  - 개방형(Open Sourced) LLM: LLaMA(Meta), Gemma(Google), Qwen(Alibaba)
    - 장점: 무료로 다운로드 및 사용이 가능하고, 모든 정보가 공개되어 있다.
    - 단점: 충분한 계산 자원이 필요하고, 폐쇄형 모델이 비해 상대적으로 성능이 낮다.
- 거대 언어 모델의 학습
  - GPT-3: "거대 언어 모델의 시초"
    - 가장 큰 버전의 GPT-3: 1750억 개의 매개변수 -> 이전 언어 모델 대비 크기가 최소 10배 이상 크고, 본격적으로 in-context learning 능력이 나타나기 시작한 언어 모델이다.
    - 학습 방법: 다음 토큰 예측(Next token prediction)
    - 학습 데이터: 3000억 토큰(4TB 텍스트 데이터: 인터넷 + 양질의 텍스트북)
    - 학습 비용: 약 150억 원
    - 한계점: 다음 토큰 예측 기반 거대 언어 모델은 사람의 지시에 대해 올바르지 않은 응답을 생성하거나, 유해한 응답을 생성할 가능성이 있다.
  - 정렬(alignment) 학습: 거대 언어 모델의 출력이 사용자의 의도와 가치를 반영하도록 하는 것.
    - 지시 학습(instruction tuning): 주어진 지시에 대해 어떤 응답이 생성되어야 하는가
      - 기존 언어 모델의 지도 추가 학습(supervised fine-tuning, SFT)의 방식과 동일하다.
      - 기존 언어 모델은 각 태스크마다 별도의 추가 학습 및 모델을 저장하는 반면, 거대 언어 모델은 주어진 입력을 받아서 이에 대한 응답을 따라 하도록 지도 추가 학습한다.
      - FLAN(Fine-tuned LAnguage Net): 거대 언어 모델을 다양한 지시 기반 입력과 이에 대한 응답으로 추가학습.
        - 학습 데이터의 다양성 증대를 위해, 각 태스크를 다양한 지시(템플렛)로 표현할 수 있다.
        - 기존 NLP 태스크 데이터를 지시 학습을 위한 데이터로 수정하여 학습 및 테스트에 활용한다.
        - 학습시에 보지 못한 지시에 대한 일반화 성능 평가를 위해, 관련 없는 태스크들을 테스트에 별도로 활용한다.
        - 결과적으로, 예시 없이도(0-shot) 새로운 지시에 대해 올바른 응답을 내놓는 성능이 크게 증가했다.
      - 성능 향상을 위한 핵심 요소
        - 학습 태스크의 개수: 다양한 종류의 지시를 학습할수록 보지 못한 지시에 대한 일반화 성능이 좋아진다.
        - 추가 학습하는 모델의 크기: 특정 규모 이하에서는 지시 학습의 효과성이 떨어진다 -> 지시를 이해하고 응답하는 것도 창발성의 일종이다.
        - 지시 방법: 자연어 지시로 사람에게 대화하듯 지시하는 것이 효과적이다.
      - 한계: 주어진 입력에 대해 적절한 하나의 응답이 있다고 가정한다. 이는 정답이 정해져 있는 객관적 태스크에서는 자연스러우나, 정답이 정해져 있는 개방형(open-ended) 태스크에서는 한계가 있다.
    - 선호 학습(preference learning): 상대적으로 어떤 응답이 더 선호되어야 하는가
      - 다양한 응답 중 사람이 더 선호하는 응답을 생성하도록 학습하는 방식이다. 응답은 모델이 생성하고, 응답간의 선호도는 사람이 제공한다. - ChatGPT의 핵심 알고리즘이다.
      - RLHF(Reinforcement Learning from Human Feedback): 사람의 피드백을 통한 강화학습
      - 학습 과정
        - 1. 지시 학습을 통한 텍스트 파운데이션 모델의 추가학습: 실제 유저로부터 다양한 지시 입력을 수집하고, 해당 입력에 대한 훈련된 사람 주석자들이 정답 데이터들을 생성한다.
        - 2. 사람의 선호 데이터를 수집하여, 보상 모델(reward model, RM)을 학습: 주어진 입력에 대한 선택지를 모델이 생성하고, 사람이 다양한 선택지에 대한 선호도를 생성한다. 사람과 일치한 선호드를 출력할 수 있도록 보상 모델을 지도 학습한다.
        - 3. 보상이 높은 응답을 생성하도록 강화 학습을 통해 추가 학습: 1, 2번 과정에서 보지 못한 질문에 대해 사람의 추가적인 개입 없이 학습된 모델들을 통해 추가 학습을 진행하고, 지시 학습된 모델을 보상 모델 기반 강화 학습을 통해 한번 더 추가 학습한다. 
- 거대 언어 모델의 추론
  - 디코딩 알고리즘
    - LLM의 자동회귀 생성(Auto-regressive generation)
      - 학습이 완료된 거대 언어 모델은 순차적 추론을 통한 토큰별 생성 방식으로 응답을 생성하고, EOS 토큰 생성 시 or 사전에 정의된 토큰 수에 도달 시 토큰 생성을 멈추고 응답을 제공한다.
      - 즉, 주어진 입력 $x = [x_1, ..., x_L]$에 대해 다음 토큰 $x_{L+1}$을 생성.
      - $\hat{p}(x)$로부터 $x_{L+1}$을 생성하는 알고리즘 -> 디코딩 알고리즘
    - 1. Greedy Decoding: 가장 확률이 높은 다음 토큰을 선택한다.
      - 장점: 사용하기 쉽다.
      - 단점: 직후만 고려하기 때문에 최종적으로 생성된 응답이 최선이 아닐 수 있다.
    - 2. Beam Search: 누적 생성 확률(지금까지 생성한 문장 전체가 나올 확률의 곱)이 높은 k개(beam size)의 후보를 동시에 고려한다. 
      - 장점: 최종적으로 좋은 응답 생성 확률이 높다.
      - 단점: 각 후보마다 LLM 추론을 수행하기 때문에 계산 비용이 많이 늘어난다.
    - 3. Sampling: 거대 언어 모델이 제공한 확률을 기준으로 랜덤하게 생성한다.
      - 장점: 다양한 응답을 생성할 수 있다.
      - 단점: 생성된 응답의 품질이 감소할 수 있다.
    - 4. Sampling with Temperature: 하이퍼 파라미터 T를 통해 거대 언어 모델이 생성한 확률 분포를 임의로 조작한다. (T>1: 확률 분포를 더 smooth하게 - 더 다양한 응답 생성, T<1: 확률 분포를 더 sharp하게 - 기존에 확률이 높은 응답에 집중)
    - 5. Top-K Sampling: 확률이 높은 K개의 토큰들 중에서만 랜덤하게 확률에 따라 샘플링한다.
      - 장점: 품질이 낮은 응답을 생성할 가능성을 줄일 수 있다.
      - 단점: 확률 분포의 모양에 상관없이 고정된 K개의 후보군을 고려한다.
    - 6. Top-P Sampling(Nucleus Sampling): K를 고정하는 대신, 누적확률(P)에 집중하여 K를 자동으로 조절한다.
      - 장점: 다양한 평가 지표에서 기존 디코딩 알고리즘들 대비 좋은 성능을 달성했다.
      - 단점: P값(일반적으로 0.9~0.95)을 사전에 설정할 필요가 있고, 경우에 따라 랜덤성이 여전할 수 있다.
  - 프롬프트 엔지니어링: 원하는 답을 얻기 위해 모델에 주어지는 입력(프롬프트)을 설계, 조정하는 기법
    - 입력 프롬프트 = 지시(instruction) + 예시(few-shot examples)
      - 지시: 감정 분류와 같은 쉬운 문제 뿐만 아니라 수학, 코딩과 같은 어려운 문제를 거대 언어 모델로 푸는 것에 많은 관심이 집중되었다.
        - Chain-of-Thought(CoT): 단순히 질문과 응답만을 예시로 활용하는 것이 아니라, 추론(reasoning) 과정도 예시에 포함시킨다. -> 거대 언어 모델(PaLM)의 추론 성능을 크게 증가시킨다. 이러한 성능 향상은 모델 크기가 커질 수록 더 확대되는 경향성이 있다.
          - 예시 기반 CoT는 강력하지만 예시를 위한 추론 과정을 수집해야 되는 문제가 있다. -> 0-shot으로도 가능할까?
        - 0-shot CoT 프롬프팅
          - 추출 문장을 통한 추론 생성 -> 주어진 질문과 생성된 추론을 통한 정답 생성
          - 기존 0-shot 프롬프팅보다 훨씬 높은 추론 성능을 달성할 수 있다. 단, 모델 크기가 임계점(약 100B)을 넘어서야 효과성이 발휘된다. 즉, 추론 능력은 거대 언어 모델의 창발성 결과라고 볼 수 있다.
- 거대 언어 모델의 평가
  - 평가(evaluation): 구축한 시스템이 실제로 잘 동작하는지 확인하는 단계
    - 평가의 3요소
      - 목표: 시스템으로 무엇을 달성하고자 하는지
      - 평가 방법: 어떤 방법으로 평가할 것인지
      - 평가 지표: 어떻게 성공 여부를 판단할 것인지
  - AI 모델의 평가
    - 학습 단계에서 본 적이 없고, 질문과 정답을 알고 있는 테스트 데이터를 사용하여 예측과 정답을 비교한다.
    - 특정 태스크에서 학습되는 기존 AI 모델들과 달리, 거대 언어 모델은 다양한 태스크에 대해 동시에 학습되기 때문에, 거대 언어 모델의 성능을 올바르게 평가하기 위해서는 많은 태스크에서의 성능을 종합적으로 판단해야 한다. 또한, 디코딩 알고리즘과 입력 프롬프트에 따라 같은 질문에 대해서도 예측이 바뀌므로 공평한 비교를 위해서는 해당 부분도 고려해야 한다.
    - 평가 방법
      - 정답이 정해져 있는 경우: 예측과 정답을 비교하여 일치도, 즉 정확도(accuracy)를 측정한다.
      - 정답이 정해져 있지 않은 경우
        - 1. 사람이 임의의 정답을 작성하고 이와 예측을 비교한다.
        - 2. 정답과 무관하게 생성 텍스트 자체의 품질만을 측정한다.
          - 단순한 등장 확률이 아니라, 여러가지 측면에서 평가하고자 한다면 거대 언어 모델로 하여금 평가 역할을 대신 수행하게 한다.
        - 3. 생성 텍스트의 상대적 선호를 평가한다.
          - 높은 평가 비용 및 시간이 요구된다. -> LLM으로 대체한다면?
          - LLM-as-judge(G-Eval): 거대 언어 모델을 통해 생성 텍스트의 상대적 선호를 평가한다. / 여전히 한계점은 남아있다.
            - 위치 편향: 특정 위치의 응답을 상대적으로 선호한다.
            - 길이 편향: 품질과 무관하게 길이가 긴 응답을 상대적으로 선호한다.
            - 자기 선호 편향: 생성 모델이 평가 모델과 같은 경우를 선호한다.
- 거대 언어 모델의 응용: 멀티모달 파운데이션 모델 
  - 다른 모달리티 데이터를 거대 언어 모델이 이해할 수 있도록 토큰화 및 추가 학습
  - 합성 데이터 생성
- 거대 언어 모델의 한계
  - 환각(Hallucination): 사실과 다르거나, 전적으로 지어낸 내용임에도 불구하고 정확한 정보와 동일한 자신감과 유창함으로 응답을 생성하는 현상.
    - 이는 거대 언어 모델이 확률적으로 다음 토큰 예측을 통해 응답을 생성하기 때문에 발생하는 현상으로, 사용자 입장에서 거대 언어 모델의 응답에 대한 진위성을 구별하기 어렵게 만든다.
  - 탈옥(Jailbreaking): 프롬프트 엔지니어링을 통해 거대 언어 모델의 정렬을 우회하는 것.
  - AI 텍스트 검출: 거대 언어 모델의 무분별한 사용
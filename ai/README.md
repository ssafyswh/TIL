Definition
- AI(Artificial Intelligence): 주어진 환경 및 데이터를 인지, 학습, 추론을 통해 목표 달성을 하도록 예측, 행동, 선택, 계획하는 시스템
- ML(Machine Learning): AI 범주 내에서 데이터로부터 학습하여 목적을 달성하는 접근 방법론. 예) 언어 모델, 이미지 분류 모델, 추천 시스템
- DL(Deep Learning): ML 범주 내에서 신경망(Neural Network) 함수를 사용한 학습 방법론 
- ML이 아닌 AI 시스템: 규칙 기반 시스템, 휴리스틱 기반 (최적화) 알고리즘

학습과 추론
- 학습(Learning): 입력(feature) - 출력(label)의 관계를 찾는 과정. 평균 관계를 하나의 함수로 표현하는 것이 목적이나 관계를 표현할 수 있는 함수가 무수히 많다.
  - 가설 공간(hypothesis space): 관계를 표현할 수 있는 모든 후보 함수들의 모음 - 피쳐 공간과 라벨 공간 위에서 정의된 함수들의 집합 F
  - 모델(model): 가설 공간 F에 속한 특정 함수 f
- 추론: 만들어진 모델을 바탕으로 결과를 예
- 함수형 모델의 형태: Y = f*(X1, X2, ... Xi) + e
  - Y: 예측하려는 라벨 변수
  - Xi: i번째 피쳐

- 머신러닝 파이프라인
  - 데이터수집 -> 전처리(EDA) -> 모델학습 -> 예측 -> 평가
  
Machine Learning(ML)
- 지도 학습: 명시적인 답이 주어진 상태로 기계학습
  - 용어 정리
    - 데이터: 입력(feature)과 정답(label)이 쌍으로 있는 데아터
    - 목표: 새 입력이 들어오면 적절한 정답을 예측하는 규칙을 학습
    - 회귀: 예측값이 수
    - 분류: 예측값이 범주
    - 예측값(y_hat): 모델이 내놓은 결과
    - 오류(error): 예측값과 라벨 간의 차이
  - 회귀(regression): 연속적인 수치에 대한 모델 예측
    - 평균제곱오차(MSE, Mean Squared Error): 각 데이터에서 정답과 예측의 평균 제곱 차이값. 큰 오류를 더 크게 벌(punishment)준다.
      - RMSE: sqrt(MSE), 데이터와 같은 단위를 쓰고 싶을 경우 사용
    - 결정계수 R^2: 라벨의 분산 중에서 특성으로 설명되는 비율. 평균만 사용하는 '단순한 예측'과 비교하여 얼마나 더 잘 맞는 모델인지 0~1 사이의 값으로 나타낸 것. 1에 가까울수록 설명력이 높다.
  - 분류(Classification): 범주 라벨에 대한 모델 예측
    - 정확도: 전체 중 맞춘 비율. 단, 이는 절대적인 안전성을 보장하지 않으며 다른 지표도 병행하여 확인할 필요가 있다.
    - 혼동행렬(Confusion Matrix): 예측과 실제 값 사이의 관계를 행렬 형태로 표현한 것.
      - TP(True Positive), TN(True Negative): 실제와 예측이 합치
      - FP(False Positive, 오탐), FN(False Negative, 누락): 실제와 예측이 불일치
      - 정밀도(precision): TP / (TP + FP)
      - 재현율(sensitivity, recall): TP / (TP + FN)
      - F1-score: 정밀도와 재현율의 조화평균, F1 = 2 * ((정밀도 * 재현율)/(정밀도 + 재현율))
  - 학습 모델의 성능 평가
    - 오버피팅(overfitting, 과적합): 훈련 데이터의 우연한 패턴/잡음까지 외워버려서 훈련에서는 잘 맞지만 테스트에서는 성능이 나빠지는 현상.
      - 표본 의존,불안성: 훈련 데이터는 모집단의 일부 표본이기 때문에 우연한 잡음이 섞일 수 있다. 이것에만 과하게 맞추어 학습할 경우 샘플 몇개만 바뀌어드 예측이 크게 흔들린다.
      - 일반화 실패: 보지 못한 데이터에 대한 오류가 커질 수 있다. 모집단 성능과 격차가 벌어진다.
    - 언더피팅(underfitting): 모델이 단순하거나 학습이 완료되지 않은 경우. 중요한 패턴을 놓칠 가능성이 높다.
    - 테스트 예측오류 계산
      - 이상적 케이스: 충분히 큰 별도 테스트 데이터셋을 마련하기. 현실에서는 테스트만을 위한 데이터를 갖기에 데이터 자체가 부족할 수 있다.
      - 대안: 재표본화(resampling)를 통한 테스트 오류 추정
        - 데이터를 나눠 여러 번 훈련 -> 평가를 반복하여 테스트 오류를 가늠한다.
        - 별도의 테스트 데이터 없이 데이터를 더 효율적으로사용하여 일반화 오차를 추정할 수 있다.
        - 검증셋(validation set, 홀드아웃) 방법
          - 가용 샘플들을 무작위로 훈련셋과 검증셋(hold-out)으로 분할하여 훈련셋으로는 모델 적합, 검증셋으로는 예측 후 검증 오류를 계산한다. 검증 오류의 경우 일반적으로 정량 반응은 MSE, 범주 반응은 오분류율(또는 F1-score)을 측정한다.
          - 검증 절차: 데이터 순서를 무작위로 셔플링 후 두 부분으로 분할하여 학습은 훈련셋에서, 성능평가는 검증셋에서 수행한다.
        - K-겹 교차검증(K-fold Cross Validation)
- 비지도 학습: 정답(label) 없이 데이터의 구조, 패턴, 집단(잠재적 서브그룹)을 찾아내는 학습
  - 대표 과제: 군집화(clustering), 차원축소(PCA), 밀도추정/이상치 탐지
  - 출력 형태: 정답 예측이 아닌 구조/요약/표현(embedding)
  - clustering: 데이터 안에서 하위 집단(cluster)을 찾는 기법들의 총칭
    - 목표: 집단 내부는 서로 유사, 집단 간은 상이하도록 데이터를 분할한다.
    - 클러스터링 기법: K-means, 계층적 군집(hierarchical)
      - K-means 클러스터링: 클러스터 수(K)를 미리 정한 후 분할한다.
        - 목표: 클러스터 내부 변동(Within-Cluster Variation)이 작은 분할이 되도록, 즉 클러스터 내부 변동의 합이 최소가 되도록 분할을 찾는다.
        - 알고리즘
          - 1. 초기화: 관측치들에 무작위로 1 ~ K 클러스터를 임시로 부여
          - 2. 반복(할당이 더 이상 바뀌지 않을때 까지)
            - a. 각 클러스터의 중심(centroid) 계산(특성 평균 벡터)
            - b. 각 관측치를 가장 가까운 중심의 클러스터에 재할당(거리 예: 유클리드)
          - 반복을 거듭함에 따라 목표함수 값을 감소시킨다.
    - 계층적 군집(Hierarchical Clustering)
      - k-means vs hierarchical
        - k-means는 클러스터 수를 미리 지정해야 하는 단점이 존재한다.
        - 계층적 군집은 군집 수를 고정하지 않고 전체 구조를 덴드로그램으로 제공
      - 알고리즘(상향식)
        - 1. n개 관측에 대해 쌍별 비유사도 계산, 각 관측치를 하나의 클러스터로 시작
        - 2. i=n, n-1, ... 2에 대해 반복
          - a. i개 클러스터 간 쌍별 비유사도를 모두 계산해 가장 유사한 두 클러스터를 병합
          - b. 병합후 남은 i-1개 클러스터 사이의 새 비유사도를 다시 계산
        - 계층적 군집 병합: 데이터들이 점차 큰 클러스터로 합쳐지는 과정. 매 단계에서 클러스터 간의 병합이 이루어지며 1개의 단일 클러스터가 될때까지 진행한다.
          - 매 단계에서 모든 클러스터 쌍 간의 거리를 계산해야 하므로 데이터가 많은 경우 K-means에 비하여 계산량이 많다.
        - link의 유형 - 군집 간 거리의 결정
          - single link(최소 거리): 두 클러스터 내 데이터 쌍별 거리 중 최소값
          - complete link(최대 거리): 두 클러스터 내 데이터 쌍별 거리 중 최대값
          - average link(평균 거리): 두 클러스터 내 데이터 쌍별 거리의 평균
    - 클러스터링 체크리스트
      - 스케일링: 표준화(평균 0, 표준편차 1로 입력 변수 변환)가 필요하다. 변수 단위 차이의 영향이 크기 때문에.
      - 몇 개의 클러스터가 적합한가?: 두 방식 모두 일반적으로 합의된 정답이 없다. 따라서 단일 시도가 아닌 다회차의 시도가 권장된다.
- 강화 학습: agent가 주어진 state에 대해 어떤 action을 취하면 reward를 얻으면서 학습

---
선형 회귀
- 입력 변수와 출력 변수 사이의 관계를 직선형태로 근사하여 예측하는 통계적 방법으로, 지도학습의 가장 기초가 되는 접근 중 하나이다. 단순해 보이지만, 개념적으로도 실무적으로도 매우 유용한 방식이다.
- 단순선형회귀(simple linear regression): 한개의 설명변수(X)와 하나의 반응변수(Y)에 사이의 관계를 가장 잘 설명할 수 있는 직선 ŷ을 찾는 방법.
  - 모형 가정: Y = β0 + β1X + ε
  - 최소제곱법(least square): 실제 관측값과 예측값의 차이(잔차, residual)를 제곱해 합한 값인 잔차제곱합(rss)을 최소화하는 방법.
- 다중선형회귀(multiple linear regression): 독립 변수가 여러개 존재할 때 사용하는 회귀분석 기법
  - 모형 가정 ŷi = β0 + β1xi1 + β2xi2 + ... + βpxip
- 주의점
  - 훈련 데이터에서의 성능: 회귀식을 만들때 최소제곱 해는 훈련 데이터만 보고 계산되는데, 학습에 사용된 훈련 데이터에서는 fitting이 잘 되어 있을 가능성이 높으나, 이는 테스트 성능의 과소평가를 유발할 가능성이 높다.
  - 테스트 성능 평가: 선형회귀도 변일반화 성능을 확인하기 위해서 훈련에 사용되지 않은 새로운 테스트 데이터에 적용해볼 필요가 있다. 수가 많거나 고차항을 사용할 경우 과적합 문제의 발생 가능성이 여전히 존재한다. 검증/교차검증을 통해서 적절한 적합을 찾을 수 있다.

---
분류(classification)
- 정해진 범주 중 하나로 지정하는 것.
- 범주형 변수: 수치의 크고 작음이 아니라 유한한 범주로 표현하는 변수
- 선형회귀는 예측값이 제한된 값(0~1 사이)을 갖게 할 수 없기 때문에 확률로 쓰기 부적절하다.
- 따라서, 시그모이드(sigmoid)함수를 활용하여 0~1 범위 내 확률값 예측을 보장할 수 있는 로지스틱 회귀 방식을 사용한다.
- 로지스틱 회귀(logistic regression)
  - sigmoid 함수: $y = \dfrac{e^z}{1 + e^z} = \dfrac{1}{1 + e^{-z}}$
  - sigmoid 함수에 z = β0 + β1x 식을 대입하고 확률 표기 p(x)를 활용하여 로지스틱 회귀의 모형식을 표현한다.
  - 로지스틱 함수 $p(x; \beta) = \dfrac{e^{\beta_0 + \beta_1 x}}{1 + e^{\beta_0 + \beta_1 x}}$
  - 오즈(odds): 성공(y=1)이 실패(y=0)에 확률에 비해 몇 배 더 높은지 나타내는 수치.
  $odds = \dfrac{p(y = 1|x)}{p(y = 0|x)} = \dfrac{p(y = 1|x)}{1 - p(y = 1|x)}$
  - 로짓 변환(logit, log odds): odds에 log를 취한 함수 형태. 로지스틱 모형에 로짓 변환을 취하면 선형 모형을 얻을 수 있다.
  - 우도(likelihood): 현재 확률 함수가 데이터를 얼마나 잘 설명하는지를 나타내는 지표. 모델의 학습은 우도 값을 높여 최대화가 되는 것을 목표로 하며 이를 MLE(Maximus Likelihood Estimation)이라 한다.

---
신경망모델
- 단순(1D) 선형모델 학습: 순차적으로 모수(parameter)를 조정하면서 찾아내는 선형회귀
- shallow network: piecewise-linear하게 모델을 근사하기
- 손실함수(loss function): 모델이 얼마나 잘못 예측하는지를 측정하는 함수
- 경사하강(gradient descent) 알고리즘: 손실함수 L[Φ]를 최소화하기 위해 파라미터 Φ를 반복적으로 갱신하는 알고리즘
  - 기울기 계산: 손실함수 L[Φ]를 파라미터 Φ에 대해 편미분 진행. 미분값의 반대방향으로 이동하면 손실함수가 줄어든다.
  - 과정 요약
    - 데이터 수집
    - 손실함수 구현(3D그래프 -> 2D등고선)
    - 선형함수 업데이트
  - Convex vs Non-convex
    - convex: 곡선이 항상 아래로 볼록(이계도함수가 항상 >=0). 그래프 위 임의 두점을 잇는 직선이 그래프 위 또는 같은 위치에 있음. 전역 최소값이 유일하기 때문에 최적화가 쉽다.
    - Non-convex: 곡선에 위로 볼록한 구간과 아래로 볼록한 구간이 혼재되어있는 경우. 두 점을 잇는 직선의 일부가 그래프 아래로 내려가는 구간이 존재. 여러개의 지역 최소값 또는 새들점이 존재하여 최적화가 어렵다.
  - 확률적 경사 하강법(Stochastic Gradient Descent, SGD)
    - Non-convex 문제에서 지역 최소점에 빠지기 쉬운 문제를 해결하기 위한 방식. 
    - 매 스텝마다 전체 데이터에 대한 미분값을 구하여 업데이트한다.(필연적으로 스텝별 개산양이 많아진다.) -> 이에 대한 대안으로, 전체 데이터를 한번에 쓰는 대신 무작위로 선택한 데이터 샘플을 사용한다.
역전파(Backpropagation)

---
워드 임베딩
- 원-핫 인코딩
  - 규칙 기반 혹은 통계적 자연어처리 연구의 대다수는 단어를 원자적 기호로 취급한다. 벡터 공간 관점에서 이는 한 원소만 1이고 나머지는 모두 0인 벡터를 의미한다. 이를 원-핫(one-hot) 표현이라 부르고, 단어를 원-핫 표현으로 바꾸는 과정을 원-핫 인코딩(one-hot encoding)이라 한다.
    - 데이터베이스에 따른 차원 수(단어 사전의 크기): 음성 데이터(2만) - Penn Treebank(PTB) 코퍼스(5만) - big vocab(50만) - Google 1T(1300만)
  - 문제점:
    - 검색 쿼리 벡터와 대상이 되는 문서 벡터들이 서료 직교하게 되어, 원-핫 벡터로는 유사도를 측정할 수 없다.
    - 차원의 저주(curse of dimensionality): 고차원의 희소 벡터를 다루기 위해서는 많은 메모리를 요구하고 차원이 커질수록 데이터가 점점 더 희소(sparse)해져 활용이 어렵다.
    - 의미적 정보 부족: 비슷한 단어라도 유사한 벡터로 표현되지 않는다. 예를 들어, '은행'과 '금융'은 의미적으로 밀접하지만, 원-핫 인코딩에서는 전혀 무관한 벡터로 취급된다.
- 워드 임베딩: 단어를 단어들 사이의 의미적 관계를 포착할 수 있는 밀집(dense)되고 연속적/분산적(distributed) 벡터 표현으로 나타내는 방법이다. 원-핫 인코딩에선 유사성이 있는 단어더라도 완전히 독립적인 벡터로 표현되는 반면, 워드 임베딩에선 두 단어의 벡터가 공간상 서로 가깝게 위치시켜 의미적 유사성을 반영할 수 있다.
  - Word2Vec: 2013년 구글에서 개발한 워드 임베딩 기법. 간단한 인공 신경망을 이용하여 단어의 표현을 학습한다.
    - 아이디어: 각 단어와 그 주변 단어들 간의 관계를 예측한다.
    - 알고리즘
      - Skip-grams(SG) 방식: 중심 단어를 통해 주변 단어들을 예측하는 방법이다. 
        - window size: 중심 단어 주변 몇개까지를 문맥으로 볼 것인가?
        - 장점
          - 단어의 위치에 크개 구애받지 않는다.  
          - 적은 데이터에도 잘 동작한다.
          - 희귀 단어나 구 표현에 강하다.
        - 단점: 학습 속도가 느리다.
      - Continuous Bag of Words(CBOW) 방식: 주변 단어들을 통해 중심 단어를 예측하는 방법이다. 문맥 단어들의 집합으로 중심 단어를 맞춘다.
        - 장점
          - 학습 속도가 빠르다.
          - 자주 나오는 단어에 강하다.
        - 단점: 희귀 단어 표현에 약하다.
- 순차적 데이터: 데이터가 입력되는 순서와 이 순서를 통해 입력되는 데이터들 사이의 관계가 중요한 데이터.
  - 특징
    - 데이터의 순서가 바뀌면 의미가 달라진다.
    - 장기 의존성(Long-term dependency): 멀리 떨어진 과거의 정보가 현재/미래에 영향을 준다.
    - 가변 길이(variable length): 데이터의 길이와 단어의 수가 일정치 않다.
  - 따라서, 순차적 데이터를 처리하려면 일반적인 모델들로는 불가능하고, sequential model이 필요하다.
    - RNN, LSTM, Transformer
- RNN(Recurrent Neural Network)
  - 전통적인 신경망과 달리, RNN은 이전 시점의 정보를 담는 hidden state를 갖는다. 따라서, 입력 시퀀스 벡터 x를 처리할 때, 각 시점마다 recurrence 수식을 적용하여 hidden state를 업데이트한다.
  - hidden state: $h_t = f_w(h_{t-1}, x_t)$
  - 특징
    - 한번에 하나의 요소를 처리하고 정보를 앞으로 전달한다. 이를 펼쳐서 보면 각 층이 하나의 시점을 나타내는 깊은 신경망처럼 보인다.
    - hidden state를 유지하면서 가변길이 데이터를 처리할 수 있다.
    - 과거 입력에 영향을 받는다.
  - 한계점 - 기울기 소실(vanishing gradient) 문제: 딥러닝에서 역전파 시 앞쪽 층의 기울기가 0에 가까워져서 장기 의존성 학습이 어려워지는 현상.
    - 역전파 과정에서 작은 값들이 계속 곱해지고, 과거 시점에서 온 오차 신호는 갈수록 더 작은 기울기를 갖게 된다. 즉, 파라미터들이 장기 의존성은 학습하지 못하고 단기 의존성만 포착하게 된다.
  - LSTM(Long-Short Term Memory): 기울기 소실 문제를 해결하기 위해 제안된 RNN의 한 종류
    - 시점 t에서 RNN은 길이가 n인 벡터 hidden state $h_t$와 cell state $C_t$를 갖는다.
    - LSTM은 cell state에서 정보를 읽고(read), 지우고(erase), 기록(write)할 수 있다.
    - 3가지 게이트를 통해 어떤 정보를 조작할지 결정한다.
      - Forget gate: 이전 cell state에서 무엇을 버리고 무엇을 유지할 지 결정한다.
      - Input gate: 새 정보 중 얼마나 cell state에 쓸지 결정한다.
      - Output gate: cell state 중 얼마나 hidden state로 내보낼지 결정한다.
---
언어모델
- 인간의 두뇌가 자연어를 생성하는 능력을 모방하는 모델. 단어 시퀀스 전체에 확률을 부여하여 문장의 자연스러움을 측정한다.
- N-gram 언어모델
  - n-gram: 연속된 n개의 단어 묶음
  - 다양한 n-gram이 얼마나 자주 등장하는지 통계를 수집하고, 이를 활용해 다음 단어를 예측한다.
- Nerual Machine Translation: 인공 신경망을 이용해 기계 번역을 수행하는 방법.
  - Seq2Seq(sequence-to-sequence): 인공 신경망 번역에 사용되는 두개의 RNN으로 이루어진 신경망 구조.
    - 번역 문제는 입출력의 길이가 다를 수 있기 때문에 길이가 다른 시퀀스 간의 매핑을 처리할 수 있어야 한다.
    - 입력 시퀀스를 한 타임스텝씩 읽어 고정된 차원의 큰 벡터 표현을 얻어내는 encoder와 얻은 벡터로부터 출력 시퀀스를 생성하는 decoder, 두 LSTM을 사용한다.


---
이미지 기반 학습 모델
- 완전 연결층(FCN, Fully-Connected Layer): 입력을 받아서 출력으로 변환하는 신경망의 기본 모듈
- 합성곱 레이어(CNN, Convolution Layer): 입력 이미지를 필터와 연산하여 특징 맵(feature map)을 뽑아내는 모듈. 1차원 구조로 변환하는 FCN과 달리 3차원 구조를 그대로 보존하면서 연산한다. 이 때, 필터의 깊이는 입력과 같아야 한다.
- 수용 영역(Receptive Field): CNN이 이미지를 처리하면서 한번에 볼수 있는 영역의 크기
  - CNN 레이어는 이미지의 작은 부분인 지역 정보를 추출하는데 유리하게 셜게되었다. 그러나, 이미지를 활용하는 다양한 작업에서는 이미지 전체(맥락) 의미 파악이 필요하다. 따라서, 지역정보 + 이미지 전체의 맥락을 이해 및 활용하기 위한 설계가 필요하다.
  - 고해상도 이미지를 처리할 때, 많은 레이어를 통과해야 하므로 연산, 비용, 학습 가능성을 고려하면 비실용적이다. 이는 입력 사이즈를 줄여 모델에 입력함으로써 해결 가능하다.
  -> 풀링(pooling)
    - 연산 효율성 확보: CNN 레이어의 출력을 줄여 연산 효율성을 확보할 수 있다.
    - 위치 변화 강건성: 입력 내 객체 위치가 다소 변해도 동일한 출력을 제공한다.
    - 맥스풀링: 정해진 커널 사이즈로 이미지를 나누어 각 영역 내 가장 큰 값을 선택하는 연산
    - 풀링 한계 개선 - 스트라이드 합성곱: 필터를 1칸씩이 아닌 스트라이드 값(S)만큼 이동한 후 출력 연산을 행한다.


---
foundation model
- 기계학습 모델의 이상과 현실
  - 이상: AI모델이 세상에서 발생 가능한 모든 데이터와 그 설명을 모두 기억하고 있음.
  - 현실: AI모델의 데이터를 패턴화하여 압축하고 그 과정에서 비슷함과 다름을 파악하고 패턴을 익히면서 새로운 데이터에 대한 일반화 능력이 생긴다.
- 파운데이션 모델: 대규모 데이터를 폭넓게 학습한 후, 다양한 문제에 빠르게 적응할 수 있는 범용 대형 AI모델.
  - 특징
    - 대규모: 트랜스포머 모델 + 대규모 언어 데이터 학습
      - 태스크에 상관없이 비슷한 패턴들이 등장하고 있다.
      - 주로 비지도학습(쉬운 데이터 수집 + 대규모 학습)으로 훈련된 모델들도 많이 등장
    - 적응성: 높은 파인튜닝 성능(높은 태스크 적응 성능)
    - 범용성: 다양한 작업, 한정되지 않는 출력 지원
  - 과거에는 매번 모델을 새로 학습했지만, 이제는 잘 학습된 모델들을 얼마나 잘 활용하는지가 핵심. 그러나, 파운데이션 모델 하나를 확보하는데 투여되는 계산 리소스는 일부 대규모 인프라 이에외는 감당하기 어렵다. 
Definition
- AI(Artificial Intelligence): 주어진 환경 및 데이터를 인지, 학습, 추론을 통해 목표 달성을 하도록 예측, 행동, 선택, 계획하는 시스템
- ML(Machine Learning): AI 범주 내에서 데이터로부터 학습하여 목적을 달성하는 접근 방법론. 예) 언어 모델, 이미지 분류 모델, 추천 시스템
- DL(Deep Learning): ML 범주 내에서 신경망(Neural Network) 함수를 사용한 학습 방법론 
- ML이 아닌 AI 시스템: 규칙 기반 시스템, 휴리스틱 기반 (최적화) 알고리즘

학습과 추론
- 학습(Learning): 입력(feature) - 출력(label)의 관계를 찾는 과정. 평균 관계를 하나의 함수로 표현하는 것이 목적이나 관계를 표현할 수 있는 함수가 무수히 많다.
  - 가설 공간(hypothesis space): 관계를 표현할 수 있는 모든 후보 함수들의 모음 - 피쳐 공간과 라벨 공간 위에서 정의된 함수들의 집합 F
  - 모델(model): 가설 공간 F에 속한 특정 함수 f
- 추론: 만들어진 모델을 바탕으로 결과를 예
- 함수형 모델의 형태: Y = f*(X1, X2, ... Xi) + e
  - Y: 예측하려는 라벨 변수
  - Xi: i번째 피쳐

- 머신러닝 파이프라인
  - 데이터수집 -> 전처리(EDA) -> 모델학습 -> 예측 -> 평가
  
Machine Learning(ML)
- 지도 학습: 명시적인 답이 주어진 상태로 기계학습
  - 용어 정리
    - 데이터: 입력(feature)과 정답(label)이 쌍으로 있는 데아터
    - 목표: 새 입력이 들어오면 적절한 정답을 예측하는 규칙을 학습
    - 회귀: 예측값이 수
    - 분류: 예측값이 범주
    - 예측값(y_hat): 모델이 내놓은 결과
    - 오류(error): 예측값과 라벨 간의 차이
  - 회귀(regression): 연속적인 수치에 대한 모델 예측
    - 평균제곱오차(MSE, Mean Squared Error): 각 데이터에서 정답과 예측의 평균 제곱 차이값. 큰 오류를 더 크게 벌(punishment)준다.
      - RMSE: sqrt(MSE), 데이터와 같은 단위를 쓰고 싶을 경우 사용
    - 결정계수 R^2: 라벨의 분산 중에서 특성으로 설명되는 비율. 평균만 사용하는 '단순한 예측'과 비교하여 얼마나 더 잘 맞는 모델인지 0~1 사이의 값으로 나타낸 것. 1에 가까울수록 설명력이 높다.
  - 분류(Classification): 범주 라벨에 대한 모델 예측
    - 정확도: 전체 중 맞춘 비율. 단, 이는 절대적인 안전성을 보장하지 않으며 다른 지표도 병행하여 확인할 필요가 있다.
    - 혼동행렬(Confusion Matrix): 예측과 실제 값 사이의 관계를 행렬 형태로 표현한 것.
      - TP(True Positive), TN(True Negative): 실제와 예측이 합치
      - FP(False Positive, 오탐), FN(False Negative, 누락): 실제와 예측이 불일치
      - 정밀도(precision): TP / (TP + FP)
      - 재현율(sensitivity, recall): TP / (TP + FN)
      - F1-score: 정밀도와 재현율의 조화평균, F1 = 2 * ((정밀도 * 재현율)/(정밀도 + 재현율))
  - 학습 모델의 성능 평가
    - 오버피팅(overfitting, 과적합): 훈련 데이터의 우연한 패턴/잡음까지 외워버려서 훈련에서는 잘 맞지만 테스트에서는 성능이 나빠지는 현상.
      - 표본 의존,불안성: 훈련 데이터는 모집단의 일부 표본이기 때문에 우연한 잡음이 섞일 수 있다. 이것에만 과하게 맞추어 학습할 경우 샘플 몇개만 바뀌어드 예측이 크게 흔들린다.
      - 일반화 실패: 보지 못한 데이터에 대한 오류가 커질 수 있다. 모집단 성능과 격차가 벌어진다.
    - 언더피팅(underfitting): 모델이 단순하거나 학습이 완료되지 않은 경우. 중요한 패턴을 놓칠 가능성이 높다.
    - 테스트 예측오류 계산
      - 이상적 케이스: 충분히 큰 별도 테스트 데이터셋을 마련하기. 현실에서는 테스트만을 위한 데이터를 갖기에 데이터 자체가 부족할 수 있다.
      - 대안: 재표본화(resampling)를 통한 테스트 오류 추정
        - 데이터를 나눠 여러 번 훈련 -> 평가를 반복하여 테스트 오류를 가늠한다.
        - 별도의 테스트 데이터 없이 데이터를 더 효율적으로사용하여 일반화 오차를 추정할 수 있다.
        - 검증셋(validation set, 홀드아웃) 방법
          - 가용 샘플들을 무작위로 훈련셋과 검증셋(hold-out)으로 분할하여 훈련셋으로는 모델 적합, 검증셋으로는 예측 후 검증 오류를 계산한다. 검증 오류의 경우 일반적으로 정량 반응은 MSE, 범주 반응은 오분류율(또는 F1-score)을 측정한다.
          - 검증 절차: 데이터 순서를 무작위로 셔플링 후 두 부분으로 분할하여 학습은 훈련셋에서, 성능평가는 검증셋에서 수행한다.
        - K-겹 교차검증(K-fold Cross Validation)
- 비지도 학습: 정답(label) 없이 데이터의 구조, 패턴, 집단(잠재적 서브그룹)을 찾아내는 학습
  - 대표 과제: 군집화(clustering), 차원축소(PCA), 밀도추정/이상치 탐지
  - 출력 형태: 정답 예측이 아닌 구조/요약/표현(embedding)
  - clustering: 데이터 안에서 하위 집단(cluster)을 찾는 기법들의 총칭
    - 목표: 집단 내부는 서로 유사, 집단 간은 상이하도록 데이터를 분할한다.
    - 클러스터링 기법: K-means, 계층적 군집(hierarchical)
      - K-means 클러스터링: 클러스터 수(K)를 미리 정한 후 분할한다.
        - 목표: 클러스터 내부 변동(Within-Cluster Variation)이 작은 분할이 되도록, 즉 클러스터 내부 변동의 합이 최소가 되도록 분할을 찾는다.
        - 알고리즘
          - 1. 초기화: 관측치들에 무작위로 1 ~ K 클러스터를 임시로 부여
          - 2. 반복(할당이 더 이상 바뀌지 않을때 까지)
            - a. 각 클러스터의 중심(centroid) 계산(특성 평균 벡터)
            - b. 각 관측치를 가장 가까운 중심의 클러스터에 재할당(거리 예: 유클리드)
          - 반복을 거듭함에 따라 목표함수 값을 감소시킨다.
    - 계층적 군집(Hierarchical Clustering)
      - k-means vs hierarchical
        - k-means는 클러스터 수를 미리 지정해야 하는 단점이 존재한다.
        - 계층적 군집은 군집 수를 고정하지 않고 전체 구조를 덴드로그램으로 제공
      - 알고리즘(상향식)
        - 1. n개 관측에 대해 쌍별 비유사도 계산, 각 관측치를 하나의 클러스터로 시작
        - 2. i=n, n-1, ... 2에 대해 반복
          - a. i개 클러스터 간 쌍별 비유사도를 모두 계산해 가장 유사한 두 클러스터를 병합
          - b. 병합후 남은 i-1개 클러스터 사이의 새 비유사도를 다시 계산
        - 계층적 군집 병합: 데이터들이 점차 큰 클러스터로 합쳐지는 과정. 매 단계에서 클러스터 간의 병합이 이루어지며 1개의 단일 클러스터가 될때까지 진행한다.
          - 매 단계에서 모든 클러스터 쌍 간의 거리를 계산해야 하므로 데이터가 많은 경우 K-means에 비하여 계산량이 많다.
        - link의 유형 - 군집 간 거리의 결정
          - single link(최소 거리): 두 클러스터 내 데이터 쌍별 거리 중 최소값
          - complete link(최대 거리): 두 클러스터 내 데이터 쌍별 거리 중 최대값
          - average link(평균 거리): 두 클러스터 내 데이터 쌍별 거리의 평균
    - 클러스터링 체크리스트
      - 스케일링: 표준화(평균 0, 표준편차 1로 입력 변수 변환)가 필요하다. 변수 단위 차이의 영향이 크기 때문에.
      - 몇 개의 클러스터가 적합한가?: 두 방식 모두 일반적으로 합의된 정답이 없다. 따라서 단일 시도가 아닌 다회차의 시도가 권장된다.
- 강화 학습: agent가 주어진 state에 대해 어떤 action을 취하면 reward를 얻으면서 학습



# Generative AI 
- ChatGPT: Generative(생성 모델) / Pre-trained(사전 훈련) / Transformer(트랜스포머 ai 모델)
  - Generative ai: 오디오, 비디오, 이미지, 텍스트, 코드, 시뮬레이션 등의 새로운 콘텐츠를 생성하는 인공지능 모델<br> 최근 언어 및 이미지 분석에서 큰 파급력을 보이고 있다.
  - Pre-trained: 거대 언어 모델(LLM) + 추가 학습 데이터 + 추가 강화 학습
  - Transformer(neural network architecture): 문장 속의 단어 간 관계를 추적해 맥락과 의미를 학습. 인간처럼 일관되고 연관성이 높은 언어를 구사하여 대화형 작업에 강점을 갖는다.
    - self-attention mechanism: 입력 데이터 간의 관계와 중요도를 계산
    - 병렬 처리 기능: RNN과 달리 순차 처리가 필요 없어 속도가 빠름
    - 스케일링 기능: 대규모 데이터 및 파라미터로 확장 가능<br> ※GPT 모델의 경우 특히 transformer의 decoder 부분만을 사용
- API(Application Programming Interface): 두 소프트웨어 또는 시스템이 서로 통신할 수 있게 하는 메커니즘.<br> 약속된 방식의 인터페이스로, 특정 규칙에 따라 데이터를 요청하고 응답하는 규칙을 제공
  - **배경지식**
    - Interface: 서로 다른 두 개의 시스템(기기, SW 등)이 정보를 교환할 때, 그 사이에 존재하는 접점
    - Application: 특정 기능을 수행하는 모든 소프트웨어
    - 웹의 구성요소: client, server, DB(database)
      - client: 서비스를 요청하는 쪽 (html, css, javascript(vue))
      - server: 요청을 받아서 처리하고 결과를 응답하는 쪽<br> static data의 경우 DB말고 서버에 저장할 수 있다. (python(django), **java(spring)**, javascript(node))
      - database: 
      - request: from client to server
      - response: from server to client or from database to server
      - query: from server to database (SQL, ORM)
      - 특징: 비연결성, 무상태
    - 프로그래밍 언어: python, java, javascript
    - framework / library: python-[django, flask], java-[spring, springboot],javascript-[angular, react, vue, svelte]
      - 프레임워크: 프로그래밍 언어를 사용하여 프로그래밍을 하는 것을 요리라는 행위 빗대어 설명하자면 프레임워크는 밀키트. 편의성면에서는 우수하나 개발자의 편의에 맞춘 세부조절이 어렵다. 또한 프레임워크를 사용하기 위한 일련의 과정을 익힐 필요가 있다.(같은 언어의 다른 프레임워크를 사용하더라도 다시 배울 필요가 있다.)
      - 라이브러리: 요리에서의 조미료. 단독 사용으로는 프로그래밍으로 성립하기 어렵다. (cf. react의 경우 그 규모가 방대하여 거의 프레임워크 급으로 동작한다고 한다.)
  - api key: api에게 요청을 보내는 application을 구별하기 위한 고유한 식별 문자열
  - 필수 파라미터
    - model: GPT 모델 이름,<br> 특정한 입력이 존재할때 , 특정한 값을 반환할 수 있도록 하는 일종의 함수
    - messages: 대화 메시지 기록
  - 응답 다양성 제어
    - temperature: 다음 토큰 예측의 다양성을 조절(0~2)<br> 확률 분포를 날카롭거나 평탄하게 만드는 역할로 응답의 창의성과 다양성을 조정하는 방법이다. 높은 확률은 더 높게, 낮은 확률은 더 낮게 조정. 모든 후보 단어의 확률을 조정하여 다양한 응답을 가능하게 한다.
    - top_p: 선택할 토큰의 확률 범위를 제한(0~1)<br> 누적 확률 기반으로 응답의 범위를 제한하는 방법이다. 확률 분포의 범위를 제한(상위 확률의 단어들만). 누적 확률 기준으로 단어 후보의 수를 제한. 응답의 신뢰성과 예측 가능성을 조정.
    - 낮은 temperature + 높은 top_p: temperature가 낮아 확률 분포의 차이가 강조됨 -> 높은 확률의 단어에 집중<br> top_p가 높아 누적 확률 범위가 넓음
  - single-turn & multi-turn
    - single-turn 대화: 한번의 질문과 한번의 응답으로 이루어진 대화 형태. 이전의 대화 내용을 기억할 수 없다.
    - multi-turn 대화: 이전의 대화를 기억함으로써 대화의 맥락을 파악하여 답변한다.
  - 프롬프트 엔지니어링
    - 1. 명시적 지시: 프롬프트 형식 지정, 맥락 제공, 페르소나 지정, 제한 사항 지정, 출력 형식 지정
    - 2. few-shot prompt: 프롬프트에 몇 가지 예시를 제공함으로써 모델이 특정한 방식으로 답변을 생성하도록 유도하는 방법.
    - 3. 생각의 사슬(chain of thoughts): 최종 답을 바로 도출하는 것이 아니라, 문제를 해결하기 위한 중간 단계를 거쳐 사고 과정을 설명함으로써 더 정확하고 일관된 답을 도출하게 한다. "단계적으로 문제를 해결하세요(let's think setp by step)"라는 프롬프트를 넣어도 생각의 사슬 효과를 일부 얻을 수 있다. 답변한 것을 토대로 "위의 답변이 올바른지 평가해보세요"라는 프롬프트를 넣으면 평가하는 과정도 생성되어 올바른 결과를 답변할 가능성이 높아진다.
    - 4. 자기 일관성(self-consistency): LLM은 확률론적 성격을 지니고 있어, 생각의 사슬과 같은 기법을 사용하더라도 단일 생성으로는 종종 잘못된 결과가 나올 수 있다. 자기 일관성은 다수의 생성을 통해 가장 빈번하게 나타나는 답을 선택함으로써 정확성을 높이는 방법이다. 단, 더 높은 계산 비용을 수반한다.
    - 5. 생각의 나무, 사고의 구조도(tree-of-thought): 생각의 사슬 기법을 확장한 방식으로, 여러가지 사고경로를 동시에 탐색하는 방법. 문제 해결 과정을 tree 구조로 표현하여 다양한 가능성을 고려하고 최적의 해결책을 찾아나간다. 인공지능이 성급하게 결정하지 않고, 여러가지 가능성을 먼저 생각한 뒤 가장 가능성이 높은 것을 선택하면서 점차 발전시키는 기술이다.
    - 6. 인터냇 검색 기반 응답: 외부 지식을 토대로 신뢰성 있는 답변을 받는 방식.